import requests
from bs4 import BeautifulSoup
import datetime
import os
import json
import hashlib
import time
import random
import re

# --- æ ¸å¿ƒé…ç½®åŒº ---
KEYWORDS = ["éŸ¶å…³å¸‚å¦‡å¹¼ä¿å¥é™¢", "éŸ¶å…³å¦‡å¹¼", "éŸ¶å…³äº§ç§‘"]
PUSH_TOKEN = os.environ.get("PUSH_TOKEN")
HISTORY_FILE = "history.json"

def get_headers():
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15'
    ]
    return {
        'User-Agent': random.choice(user_agents),
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Referer': 'https://cn.bing.com/'
    }

def contains_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fa5]', text))

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            try:
                return set(json.load(f))
            except:
                return set()
    return set()

def save_history(history_set):
    limited_history = list(history_set)[-1000:]
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(limited_history, f)

def search_cn_bing(keyword):
    results = []
    url = f"https://cn.bing.com/search?q={keyword}&cc=CN&setmkt=zh-CN&first=1"
    
    try:
        print(f"æ­£åœ¨æŠ“å–: {keyword} ...")
        resp = requests.get(url, headers=get_headers(), timeout=20)
        soup = BeautifulSoup(resp.text, 'lxml')
        
        for item in soup.find_all('li', class_='b_algo'):
            title_tag = item.find('h2')
            if not title_tag: continue
            
            link_tag = title_tag.find('a')
            if not link_tag: continue
            
            # --- ä¿®å¤ç‚¹ï¼šæ‹†åˆ†å†™æ³•ï¼Œè§£å†³ SyntaxError ---
            link = link_tag.get('href')
            if not link: continue
            # -------------------------------------
            
            title = link_tag.text.strip()
            if not contains_chinese(title): continue
            
            snippet = ""
            caption_div = item.find('div', class_='b_caption')
            if caption_div:
                p_tag = caption_div.find('p')
                snippet = p_tag.text.strip() if p_tag else ""

            results.append({
                "title": title,
                "link": link,
                "snippet": snippet,
                "source": "BingCN"
            })
    except Exception as e:
        print(f"æŠ“å–å¼‚å¸¸: {e}")
    
    return results

def send_push(content_list):
    if not content_list: return
    title = f"ğŸ“¢ {datetime.date.today()} éŸ¶å…³å¦‡å¹¼èˆ†æƒ… ({len(content_list)}æ¡)"
    content = "#### ğŸ” ç›‘æ§æ—¥æŠ¥\n------------------\n\n" + "\n\n".join(content_list)
    url = "http://www.pushplus.plus/send"
    data = {"token": PUSH_TOKEN, "title": title, "content": content, "template": "markdown"}
    requests.post(url, json=data)

def main():
    history = load_history()
    new_entries = []
    
    for keyword in KEYWORDS:
        results = search_cn_bing(keyword)
        for item in results:
            unique_str = item['link']
            uid = hashlib.md5(unique_str.encode()).hexdigest()
            if uid in history: continue
            
            history.add(uid)
            is_risk = any(w in (item['title'] + item['snippet']) for w in ["æŠ•è¯‰", "æ­»", "å·®", "é¿é›·", "äº‹æ•…"])
            emoji = "ğŸ”´" if is_risk else "ğŸ”µ"
            entry = f"{emoji} **[{item['title']}]({item['link']})**\n> {item['snippet'][:80]}..."
            new_entries.append(entry)
        time.sleep(random.uniform(2, 5))

    if new_entries:
        print(f"âœ… å‘ç° {len(new_entries)} æ¡å†…å®¹ï¼Œæ¨é€ä¸­...")
        send_push(new_entries)
        save_history(history)
    else:
        print("â­• ä»Šæ—¥æ— æ–°å†…å®¹")

if __name__ == "__main__":
    main()
