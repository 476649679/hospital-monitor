import requests
from bs4 import BeautifulSoup
import datetime
import os
import json
import hashlib
import time
import random
import re

# --- æ ¸å¿ƒé…ç½®åŒº ---
# å»ºè®®åŠ ä¸Š "åŒ»é™¢" "å…¬å‘Š" ç­‰åç¼€ï¼Œæœç´¢ç»“æœæ›´ç²¾å‡†
KEYWORDS = ["åŒ»é™¢","éŸ¶å…³ åŒ»é™¢","éŸ¶å…³å¸‚å¦‡å¹¼ä¿å¥é™¢", "éŸ¶å…³å¦‡å¹¼ä¿å¥é™¢", "éŸ¶å…³å¦‡å¹¼ æŠ•è¯‰", "éŸ¶å…³å¦‡å¹¼ é¿é›·"]

PUSH_TOKEN = os.environ.get("PUSH_TOKEN")
HISTORY_FILE = "history.json"

def get_headers():
    """
    ä¼ªè£…æˆä½äºä¸­å›½çš„ä¸­æ–‡ç”¨æˆ·
    """
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15'
    ]
    return {
        'User-Agent': random.choice(user_agents),
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8', # å…³é”®ï¼šå‘Šè¯‰æœåŠ¡å™¨æˆ‘æ˜¯ä¸­æ–‡ç”¨æˆ·
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Referer': 'https://cn.bing.com/'
    }

def contains_chinese(text):
    """åˆ¤æ–­æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œç”¨äºè¿‡æ»¤è‹±æ–‡åƒåœ¾ç»“æœ"""
    return bool(re.search(r'[\u4e00-\u9fa5]', text))

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            try:
                return set(json.load(f))
            except:
                return set()
    return set()

def save_history(history_set):
    limited_history = list(history_set)[-1000:]
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(limited_history, f)

def search_cn_bing(keyword):
    """
    é’ˆå¯¹ cn.bing.com çš„ä¼˜åŒ–æœç´¢
    """
    results = []
    # å¼ºåˆ¶ä½¿ç”¨ cn.bing.comï¼Œå¹¶åŠ ä¸Š &cc=CN å‚æ•°å¼ºåˆ¶ä¸­å›½åŒº
    url = f"https://cn.bing.com/search?q={keyword}&cc=CN&setmkt=zh-CN&first=1"
    
    try:
        print(f"æ­£åœ¨æŠ“å–: {keyword} ...")
        resp = requests.get(url, headers=get_headers(), timeout=20)
        
        if resp.status_code != 200:
            print(f"âŒ è®¿é—®å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status_code}")
            return []

        soup = BeautifulSoup(resp.text, 'lxml')
        
        # è§£æ Bing æœç´¢ç»“æœåˆ—è¡¨
        for item in soup.find_all('li', class_='b_algo'):
            title_tag = item.find('h2')
            if not title_tag: continue
            
            link_tag = title_tag.find('a')
            if not link_tag: continue
            
            link = link_tag.get('href')
            if not link: continue
            
            title = link_tag.text.strip()
            
            # --- å…³é”®è¿‡æ»¤å™¨ ---
            # 1. å¦‚æœæ ‡é¢˜é‡Œæ²¡æœ‰ä¸­æ–‡ï¼Œè¯´æ˜æ˜¯è‹±æ–‡åƒåœ¾ç»“æœï¼Œä¸¢å¼ƒ
            if not contains_chinese(title):
                continue
            
            # è·å–æ‘˜è¦
            snippet = ""
            caption_div = item.find('div', class_='b_caption')
            if caption_div:
                p_tag = caption_div.find('p')
                snippet = p_tag.text.strip() if p_tag else ""
            
            # å¦‚æœæ‘˜è¦é‡Œä¹Ÿæ²¡æœ‰å…³é”®è¯ï¼Œå¯èƒ½æ˜¯å¹¿å‘Šï¼Œè¿›ä¸€æ­¥è¿‡æ»¤
            if keyword.split()[0] not in title and keyword.split()[0] not in snippet:
                 # ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œé˜²æ­¢æ¼æŠ“ï¼Œè¿™é‡Œåªåšç®€å•çš„ç›¸å…³æ€§æ‰“å°
                 pass

            results.append({
                "title": title,
                "link": link,
                "snippet": snippet,
                "source": "BingCN"
            })
            
    except Exception as e:
        print(f"æŠ“å–å¼‚å¸¸: {e}")
    
    return results

def send_push(content_list):
    if not content_list: return

    title = f"ğŸ“¢ {datetime.date.today()} éŸ¶å…³å¦‡å¹¼èˆ†æƒ… ({len(content_list)}æ¡)"
    
    content = "#### ğŸ” ç›‘æ§æ—¥æŠ¥ (CNèŠ‚ç‚¹å¢å¼ºç‰ˆ)\n"
    content += "------------------\n\n"
    content += "\n\n".join(content_list)
    
    url = "http://www.pushplus.plus/send"
    data = {
        "token": PUSH_TOKEN,
        "title": title,
        "content": content,
        "template": "markdown" 
    }
    requests.post(url, json=data)

def main():
    history = load_history()
    new_entries = []
    
    # éå†å…³é”®è¯
    for keyword in KEYWORDS:
        results = search_cn_bing(keyword)
        
        for item in results:
            # å»é‡é€»è¾‘
            unique_str = item['link']
            uid = hashlib.md5(unique_str.encode()).hexdigest()
            
            if uid in history:
                continue 
            
            history.add(uid)
            
            # ç®€å•çš„è´Ÿé¢è¯é«˜äº®
            is_risk = any(w in (item['title'] + item['snippet']) for w in ["æŠ•è¯‰", "æ­»", "å·®", "é¿é›·", "äº‹æ•…"])
            emoji = "ğŸ”´" if is_risk else "ğŸ”µ"
            
            entry = f"{emoji} **[{item['title']}]({item['link']})**\n" \
                    f"> {item['snippet'][:80]}..."
            new_entries.append(entry)
        
        # éšæœºç­‰å¾…ï¼Œé¿å…è¢«å°
        time.sleep(random.uniform(2, 5))

    if new_entries:
        print(f"âœ… å‘ç° {len(new_entries)} æ¡æœ‰æ•ˆä¸­æ–‡å†…å®¹ï¼Œæ¨é€ä¸­...")
        send_push(new_entries)
        save_history(history)
    else:
        print("â­• ä»Šæ—¥æ— æ–°å†…å®¹ï¼ˆå·²è¿‡æ»¤æ‰éä¸­æ–‡/æ— å…³é”®å†…å®¹ç»“æœï¼‰")

if __name__ == "__main__":
    main()
